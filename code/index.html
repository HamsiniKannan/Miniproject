## 1. Loading test images:

def list_images(images, cols = 2, rows = 5, cmap=None): 
plt.figure(figsize=(10, 11))
for i, image in enumerate(images):
plt.subplot(rows, cols, i+1)
#Use gray scale color map if there is only one channel 
cmap = 'gray' if len(image.shape) == 2 else cmap 
plt.imshow(image, cmap = cmap)
plt.xticks([])
plt.yticks([])
plt.tight_layout(pad=0, h_pad=0, w_pad=0) 
plt.show()

2. Color Selection:
def HSL_color_selection(image): 
#Convert the input image to HSL 
converted_image = convert_hsl(image)
#White color mask
lower_threshold = np.uint8([0, 200, 0])
upper_threshold = np.uint8([255, 255, 255])
white_mask = cv2.inRange(converted_image, lower_threshold, 
upper_threshold)
#Yellow color mask
lower_threshold = np.uint8([10, 0, 100])
upper_threshold = np.uint8([40, 255, 255])
yellow_mask = cv2.inRange(converted_image, lower_threshold, 
upper_threshold)
#Combine white and yellow masks
mask = cv2.bitwise_or(white_mask, yellow_mask) 
masked_image = cv2.bitwise_and(image, image, mask = mask)
return masked_image
25
3.Region of interest
def region_selection(image): 
mask = np.zeros_like(image)
#Defining a 3 channel or 1 channel color to fill the mask with depending on 
the input image
if len(image.shape) > 2: 
channel_count = image.shape[2]
ignore_mask_color = (255,) * channel_count 
else:
ignore_mask_color = 255
#We could have used fixed numbers as the vertices of the polygon, 
#but they will not be applicable to images with different dimesnions. 
rows, cols = image.shape[:2]
bottom_left = [cols * 0.1, rows * 0.95] 
top_left = [cols * 0.4, rows * 0.6] 
bottom_right = [cols * 0.9, rows * 0.95] 
top_right = [cols * 0.6, rows * 0.6]
vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], 
dtype=np.int32)
cv2.fillPoly(mask, vertices, ignore_mask_color) 
masked_image = cv2.bitwise_and(image, mask) 
return masked_image
4.Hough Transform
def hough_transform(image):
rho = 1
theta = np.pi/180 
threshold = 20
minLineLength = 20
maxLineGap = 300
return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = 
threshold,
minLineLength = minLineLength, maxLineGap = maxLineGap)
26
5. Averaging and extrapolating the lane lines
def average_slope_intercept(lines): 
left_lines = [] #(slope, intercept) 
left_weights = [] #(length,) 
right_lines = [] #(slope, intercept) 
right_weights = [] #(length,)
for line in lines:
for x1, y1, x2, y2 in line: 
if x1 == x2:
continue
slope = (y2 - y1) / (x2 - x1) 
intercept = y1 - (slope * x1)
length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2)) 
if slope < 0:
left_lines.append((slope, intercept)) 
left_weights.append((length))
else:
right_lines.append((slope, intercept)) 
right_weights.append((length))
left_lane = np.dot(left_weights, left_lines) / np.sum(left_weights) if 
len(left_weights) > 0 else None
right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if 
len(right_weights) > 0 else None
return left_lane, right_lane 
def pixel_points(y1, y2, line):
if line is None: 
return None
slope, intercept = line
x1 = int((y1 - intercept)/slope) 
x2 = int((y2 - intercept)/slope) 
y1 = int(y1)
y2 = int(y2)
return ((x1, y1), (x2, y2)) 
def lane_lines(image, lines):
left_lane, right_lane = average_slope_intercept(lines) 
y1 = image.shape[0]
y2 = y1 * 0.6
left_line = pixel_points(y1, y2, left_lane)
27
right_line = pixel_points(y1, y2, right_lane) 
return left_line, right_line
def draw_lane_lines(image, lines, color=[255, 0, 0], thickness=12): 
line_image = np.zeros_like(image)
for line in lines:
if line is not None:
cv2.line(line_image, *line, color, thickness)
return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)
6. Apply on video streams
def frame_processor(image):
color_select = HSL_color_selection(image) 
gray = gray_scale(color_select) 
smooth = gaussian_smoothing(gray) 
edges = canny_detector(smooth) 
region = region_selection(edges)
hough = hough_transform(region)
result = draw_lane_lines(image, lane_lines(image, hough)) 
return result
def process_video(test_video, output_video):
input_video = VideoFileClip(os.path.join('test_videos', test_video), 
audio=False)
processed = input_video.fl_image(frame_processor) 
processed.write_videofile(os.path.join('output_videos', output_video),
audio=False)
